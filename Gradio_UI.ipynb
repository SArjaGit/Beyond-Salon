{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from lib.hair import look_maker\n",
    "import gradio as gr\n",
    "from PIL import Image\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UPLOAD_DIR = \"uploaded_images\"\n",
    "os.makedirs(UPLOAD_DIR, exist_ok=True)\n",
    "#image = \"source_data/Roberta.jpg\"\n",
    "# Define the function to transform hair color\n",
    "def transform_hair(image, color):\n",
    "    \n",
    "    # Define the directory for uploaded images\n",
    "    image_path = os.path.join(UPLOAD_DIR, \"uploaded_image.jpg\")\n",
    "\n",
    "    # Save the uploaded image to a temporary file\n",
    "    image.save(image_path)\n",
    "\n",
    "    print(f\"Image saved to: {image_path}\")\n",
    "    \n",
    "    # Call the set_hair_color method with the image path and color\n",
    "    output_path = look_maker.hair_transform(color, image_path)\n",
    "\n",
    "    output_path = \"output/colored_hair.png\"\n",
    "    \n",
    "    print(f\"Output path: {output_path}\")\n",
    "\n",
    "    if output_path and os.path.exists(output_path):\n",
    "        # Load the transformed image to return it\n",
    "        transformed_image = Image.open(output_path)\n",
    "        # Clean up the temporary file\n",
    "\n",
    "        return transformed_image\n",
    "    else:\n",
    "        raise ValueError(\"Failed to generate transformed image\")\n",
    "    \n",
    "    return transformed_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://dd5ee4bcce722ab67a.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://dd5ee4bcce722ab67a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved to: uploaded_images/uploaded_image.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py310/lib/python3.10/site-packages/segment_anything/build_sam.py:105: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(f)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hair mask saved to: output/masks/hair_mask.png\n",
      "Hair mask generated at output/masks/hair_mask.png\n",
      "RGB value for orange is IntegerRGB(red=255, green=165, blue=0)\n",
      "RGB value for orange is 255 165 0\n",
      "Image saved at Output path: output/colored_hair.png\n",
      "Output path: output/colored_hair.png\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a Gradio interface\n",
    "iface = gr.Interface(\n",
    "    fn=transform_hair,\n",
    "    inputs=[\n",
    "        #gr.Image(\"source_data/Roberta.jpg\"),\n",
    "        gr.Image(type=\"pil\", label=\"Input Image\"),\n",
    "        gr.Dropdown(choices=['blue', 'red', 'green', 'yellow', 'purple', 'pink', 'orange', 'brown', 'black', 'white','gray', 'cyan', 'magenta'], label=\"Hair Color\")\n",
    "    ],\n",
    "    outputs=gr.Image(type=\"pil\", label=\"Transformed Image\"),\n",
    "    title=\"Beyond Salon\",\n",
    "    description=\"Upload an image and select a hair color to see how the color suits.\",\n",
    "    article=\"<p style='text-align: center;'>bring life to your hair!!</p>\"\n",
    ")\n",
    "\n",
    "\n",
    "# Launch the interface\n",
    "iface.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
