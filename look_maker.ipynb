{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from lib.hair import HairMaskPipeline\n",
    "import cv2\n",
    "import numpy as np\n",
    "import webcolors\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mask(input_image_path):\n",
    "    hair_mask_pipeline = HairMaskPipeline()\n",
    "\n",
    "    hair_mask_path = hair_mask_pipeline.generate_hair_mask(image_path=input_image_path, output_mask_path='output/masks/hair_mask.png')\n",
    "\n",
    "    print('Hair mask generated at', hair_mask_path)\n",
    "\n",
    "    return hair_mask_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_hair_color(color_name, input_image_path, hair_mask_path):\n",
    "\n",
    "  input_image_cv = cv2.imread(input_image_path, cv2.IMREAD_UNCHANGED)\n",
    "  hair_mask_cv = cv2.imread(hair_mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "  # Add an alpha channel to the input image if it doesn't have one\n",
    "  if input_image_cv.shape[2] == 3:\n",
    "    input_image_cv = cv2.cvtColor(input_image_cv, cv2.COLOR_BGR2BGRA)\n",
    "\n",
    "  rgb_value = webcolors.name_to_rgb(color_name)\n",
    "\n",
    "  print('RGB value for', color_name, 'is', rgb_value)\n",
    "  print('RGB value for', color_name, 'is', rgb_value.red, rgb_value.green, rgb_value.blue)\n",
    "\n",
    "  # Create a red layer with the same size as the input image\n",
    "  color_layer_cv = np.zeros_like(input_image_cv)\n",
    "  color_layer_cv[:, :, 0] = rgb_value.blue  # Set the blue channel\n",
    "  color_layer_cv[:, :, 1] = rgb_value.green  # Set the green channel\n",
    "  color_layer_cv[:, :, 2] = rgb_value.red  # Set the red channel\n",
    "\n",
    "  # Apply the red color only to the mask area\n",
    "  color_layer_cv[:, :, 3] = hair_mask_cv\n",
    "\n",
    "  # Composite the red layer onto the input image using the mask with 10% alpha\n",
    "  colored_image_cv = input_image_cv.copy()\n",
    "  alpha = 0.15\n",
    "  colored_image_cv[hair_mask_cv > 0] = cv2.addWeighted(input_image_cv[hair_mask_cv > 0], 1 - alpha, color_layer_cv[hair_mask_cv > 0], alpha, 0)\n",
    "\n",
    "  # Save the result\n",
    "  cv2.imwrite('output/colored_hair.png', colored_image_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set_hair_color('blue', 'source_data/stefan_original_photo.jpg')\n",
    "\n",
    "def hair_transform(selected_color, image_path):\n",
    "    set_hair_color(selected_color, image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1685bdd787d4d5390a3ee4f3f5f0dbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Color:', options=('blue', 'red', 'green', 'yellow', 'purple', 'pink'), value='blue')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa4dc37f2c38421588b61a04fffad780",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='source_data/stefan_original_photo.jpg', description='Image Path:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7426909ea20e4012989bb7dc0c46ccdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Apply Hair Color', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d98686f8ebb44e2969fd775c0de7e6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sarja\\AppData\\Local\\anaconda3\\envs\\py310\\lib\\site-packages\\segment_anything\\build_sam.py:105: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(f)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hair mask saved to: output/masks/hair_mask.png\n",
      "Hair mask generated at output/masks/hair_mask.png\n",
      "RGB value for blue is IntegerRGB(red=0, green=0, blue=255)\n",
      "RGB value for blue is 0 0 255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6a7fc349fc64a469952eb4d07eef7e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hair mask saved to: output/masks/hair_mask.png\n",
      "Hair mask generated at output/masks/hair_mask.png\n",
      "RGB value for yellow is IntegerRGB(red=255, green=255, blue=0)\n",
      "RGB value for yellow is 255 255 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80c76cebb77249729093b164e4b7d65d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Image not found at \"C:\\Users\\Sarja\\OneDrive - Hearst\\Pictures\\Sarath.png\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 20\u001b[0m, in \u001b[0;36mon_apply_button_clicked\u001b[1;34m(b)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_apply_button_clicked\u001b[39m(b):\n\u001b[1;32m---> 20\u001b[0m     \u001b[43mhair_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolor_dropdown\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_path_text\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 4\u001b[0m, in \u001b[0;36mhair_transform\u001b[1;34m(selected_color, image_path)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhair_transform\u001b[39m(selected_color, image_path):\n\u001b[1;32m----> 4\u001b[0m     \u001b[43mset_hair_color\u001b[49m\u001b[43m(\u001b[49m\u001b[43mselected_color\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 4\u001b[0m, in \u001b[0;36mset_hair_color\u001b[1;34m(color_name, input_image_path)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_hair_color\u001b[39m(color_name, input_image_path):\n\u001b[0;32m      2\u001b[0m   hair_mask_pipeline \u001b[38;5;241m=\u001b[39m HairMaskPipeline()\n\u001b[1;32m----> 4\u001b[0m   hair_mask_path \u001b[38;5;241m=\u001b[39m \u001b[43mhair_mask_pipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_hair_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_image_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_mask_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutput/masks/hair_mask.png\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHair mask generated at\u001b[39m\u001b[38;5;124m'\u001b[39m, hair_mask_path)\n\u001b[0;32m      7\u001b[0m   \u001b[38;5;66;03m# Read the input image and hair mask using cv2\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Sarja\\OneDrive - Hearst\\Documents\\AI&ML\\Code\\Project-3\\lib\\hair.py:57\u001b[0m, in \u001b[0;36mHairMaskPipeline.generate_hair_mask\u001b[1;34m(self, image_path, output_mask_path)\u001b[0m\n\u001b[0;32m     55\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(image_path)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m image \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 57\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage not found at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     58\u001b[0m image_rgb \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(image, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msam_predictor\u001b[38;5;241m.\u001b[39mset_image(image_rgb)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Image not found at \"C:\\Users\\Sarja\\OneDrive - Hearst\\Pictures\\Sarath.png\""
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9562706a3a1b437eabc17953548ae5a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hair mask saved to: output/masks/hair_mask.png\n",
      "Hair mask generated at output/masks/hair_mask.png\n",
      "RGB value for yellow is IntegerRGB(red=255, green=255, blue=0)\n",
      "RGB value for yellow is 255 255 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b95815e38cd4cfab7fde175f6741864",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hair mask saved to: output/masks/hair_mask.png\n",
      "Hair mask generated at output/masks/hair_mask.png\n",
      "RGB value for green is IntegerRGB(red=0, green=128, blue=0)\n",
      "RGB value for green is 0 128 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b13ca6e60f2240c7b934b976635a6c66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hair mask saved to: output/masks/hair_mask.png\n",
      "Hair mask generated at output/masks/hair_mask.png\n",
      "RGB value for green is IntegerRGB(red=0, green=128, blue=0)\n",
      "RGB value for green is 0 128 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "889bf62f2e054c0ea54f42a8741a0636",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hair mask saved to: output/masks/hair_mask.png\n",
      "Hair mask generated at output/masks/hair_mask.png\n",
      "RGB value for pink is IntegerRGB(red=255, green=192, blue=203)\n",
      "RGB value for pink is 255 192 203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab5c3cd9df004274bda4de5c0848f6b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hair mask saved to: output/masks/hair_mask.png\n",
      "Hair mask generated at output/masks/hair_mask.png\n",
      "RGB value for pink is IntegerRGB(red=255, green=192, blue=203)\n",
      "RGB value for pink is 255 192 203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32b4e5f21bf44775a496651c391411f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hair mask saved to: output/masks/hair_mask.png\n",
      "Hair mask generated at output/masks/hair_mask.png\n",
      "RGB value for red is IntegerRGB(red=255, green=0, blue=0)\n",
      "RGB value for red is 255 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3154b423c9b64b82b81946832445bb6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hair mask saved to: output/masks/hair_mask.png\n",
      "Hair mask generated at output/masks/hair_mask.png\n",
      "RGB value for green is IntegerRGB(red=0, green=128, blue=0)\n",
      "RGB value for green is 0 128 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "099c8c1ceaa448d4ac17ad1d5ec95523",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hair mask saved to: output/masks/hair_mask.png\n",
      "Hair mask generated at output/masks/hair_mask.png\n",
      "RGB value for green is IntegerRGB(red=0, green=128, blue=0)\n",
      "RGB value for green is 0 128 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a96f0372677c486484c5ce921ac688b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hair mask saved to: output/masks/hair_mask.png\n",
      "Hair mask generated at output/masks/hair_mask.png\n",
      "RGB value for red is IntegerRGB(red=255, green=0, blue=0)\n",
      "RGB value for red is 255 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8df50d484124e76b8b6b0199dfa3755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hair mask saved to: output/masks/hair_mask.png\n",
      "Hair mask generated at output/masks/hair_mask.png\n",
      "RGB value for red is IntegerRGB(red=255, green=0, blue=0)\n",
      "RGB value for red is 255 0 0\n"
     ]
    }
   ],
   "source": [
    "color_dropdown = widgets.Dropdown(\n",
    "  options=['blue', 'red', 'green', 'yellow', 'purple', 'pink'],\n",
    "  value='blue',\n",
    "  description='Color:',\n",
    ")\n",
    "\n",
    "# Create a text input for image path\n",
    "image_path_text = widgets.Text(\n",
    "  value='source_data/stefan_original_photo.jpg',\n",
    "  description='Image Path:',\n",
    ")\n",
    "\n",
    "# Create a button to apply the hair color\n",
    "apply_button = widgets.Button(\n",
    "    description='Apply Hair Color',\n",
    ")\n",
    "\n",
    "# Define the function to be called when the button is clicked\n",
    "def on_apply_button_clicked(b):\n",
    "    hair_transform(color_dropdown.value, image_path_text.value)\n",
    "\n",
    "apply_button.on_click(on_apply_button_clicked)\n",
    "\n",
    "# Display the widgets\n",
    "display(color_dropdown, image_path_text, apply_button)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
